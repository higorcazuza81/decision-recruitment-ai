{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca36618",
   "metadata": {},
   "source": [
    "# Decision - Sistema de Matching de Candidatos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fa3466",
   "metadata": {},
   "source": [
    "## Pós-Graduação em Data Analytics e Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae55c6",
   "metadata": {},
   "source": [
    "### Autor: [Janaína Cazuza](https://www.linkedin.com/in/janainacazuza/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978739b6",
   "metadata": {},
   "source": [
    "## 1. Configuração Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa9710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    RandomizedSearchCV,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_recall_curve,\n",
    "    PrecisionRecallDisplay,\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configurações\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c192189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Caminho do arquivo JSON\n",
    "caminho_arquivo = \"../data/raw/applicants.json\"\n",
    "\n",
    "# Abrir o arquivo JSON\n",
    "with open(caminho_arquivo, \"r\", encoding=\"utf-8\") as f:\n",
    "    dados_json = json.load(f)\n",
    "\n",
    "# dados_json é um dicionário, então pegamos apenas os valores (cada valor é um candidato)\n",
    "lista_candidatos = list(dados_json.values())\n",
    "\n",
    "# Agora aplicamos o json_normalize nessa lista de candidatos\n",
    "df_applicants = pd.json_normalize(lista_candidatos)\n",
    "\n",
    "# Visualizar as colunas e as primeiras linhas\n",
    "print(df_applicants.columns)\n",
    "print(df_applicants.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39425f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicants.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ea6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicants.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo JSON\n",
    "caminho_arquivo = \"../data/raw/prospects.json\"\n",
    "\n",
    "# Abrir o arquivo JSON\n",
    "with open(caminho_arquivo, \"r\", encoding=\"utf-8\") as f:\n",
    "    dados_json = json.load(f)\n",
    "\n",
    "# Converter o JSON em DataFrame básico (cada linha é uma vaga com uma lista de prospects)\n",
    "df_prospects = pd.json_normalize(list(dados_json.values()))\n",
    "\n",
    "# Explodir a coluna 'prospects' para que cada candidato fique em uma linha separada\n",
    "df_explodido = df_prospects.explode(\"prospects\").reset_index(drop=True)\n",
    "\n",
    "# Agora, cada linha da coluna 'prospects' é um dicionário — vamos normalizar essa coluna para separar os campos\n",
    "df_prospects_normalizado = pd.json_normalize(df_explodido[\"prospects\"])\n",
    "\n",
    "# Concatenar as colunas da vaga com as informações normalizadas dos candidatos\n",
    "df_prospects_final = pd.concat(\n",
    "    [df_explodido.drop(columns=[\"prospects\"]), df_prospects_normalizado], axis=1\n",
    ")\n",
    "\n",
    "# Visualizar o resultado\n",
    "print(df_prospects_final.columns)\n",
    "print(df_prospects_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08edaffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prospects_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prospects_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Carrega o arquivo jobs.json\n",
    "with open(\"../data/raw/jobs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jobs_raw = json.load(f)\n",
    "\n",
    "# 2. Transforma o dicionário em uma lista de dicionários, mantendo a chave como 'codigo_vaga'\n",
    "jobs_list = [\n",
    "    {\"codigo_vaga\": codigo, **conteudo} for codigo, conteudo in jobs_raw.items()\n",
    "]\n",
    "\n",
    "# 3. Usa json_normalize para achatar os campos aninhados\n",
    "df_jobs = pd.json_normalize(jobs_list)\n",
    "\n",
    "# 4. Visualiza as primeiras linhas\n",
    "df_jobs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be15e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efa154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prospects_final = df_prospects_final.rename(columns={\"codigo\": \"codigo_vaga\"})\n",
    "df_vagas_prospectadas = df_prospects_final.merge(df_jobs, on=\"codigo_vaga\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01953a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Colunas em df_prospects_final:\", df_prospects_final.columns)\n",
    "print(\"Colunas em df_jobs:\", df_jobs.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicants.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prospects_final[\"vaga_em_jobs\"] = df_prospects_final[\"codigo_vaga\"].isin(\n",
    "    df_jobs[\"codigo_vaga\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75847982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicants[\"informacoes_pessoais.nome\"] = (\n",
    "    df_applicants[\"informacoes_pessoais.nome\"].str.lower().str.strip()\n",
    ")\n",
    "df_vagas_prospectadas[\"nome\"] = df_vagas_prospectadas[\"nome\"].str.lower().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_vagas_prospectadas.merge(\n",
    "    df_applicants, left_on=\"nome\", right_on=\"informacoes_pessoais.nome\", how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e096d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75106e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\n",
    "    \"../data/processed/merged_data.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c407a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover duplicatas, se houver\n",
    "df_merged = df_merged.drop_duplicates()\n",
    "\n",
    "# Exemplo de padronização de colunas\n",
    "df_merged.columns = df_merged.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a843a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Linhas totais: {len(df_merged)}\")\n",
    "print(f\"Vagas únicas: {df_merged['codigo_vaga'].nunique()}\")\n",
    "print(f\"Candidatos únicos: {df_merged['nome'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Top 10 vagas com mais candidaturas\n",
    "top_vagas = df_merged[\"codigo_vaga\"].value_counts().head(10)\n",
    "print(top_vagas)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_vagas.plot(kind=\"bar\")\n",
    "plt.title(\"Top 10 vagas com mais candidaturas\")\n",
    "plt.xlabel(\"Código da vaga\")\n",
    "plt.ylabel(\"Número de candidaturas\")\n",
    "plt.show()\n",
    "\n",
    "# Status dos candidatos\n",
    "status_counts = df_merged[\"situacao_candidado\"].value_counts()\n",
    "print(status_counts)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "status_counts.plot(kind=\"bar\", color=\"skyblue\")\n",
    "plt.title(\"Distribuição do status dos candidatos\")\n",
    "plt.xlabel(\"Status\")\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Converter a coluna para string e tratar nulos\n",
    "df_merged[\"situacao_candidado\"] = (\n",
    "    df_merged[\"situacao_candidado\"].astype(str).replace(\"nan\", \"\")\n",
    ")\n",
    "\n",
    "# 2. Definir status de sucesso\n",
    "status_sucesso = [\n",
    "    \"Contratado pela Decision\",\n",
    "    \"Contratado como Hunting\",\n",
    "    \"Aprovado\",\n",
    "    \"Proposta Aceita\",\n",
    "]\n",
    "\n",
    "# 3. Criar target binário\n",
    "df_merged[\"target\"] = df_merged[\"situacao_candidado\"].isin(status_sucesso).astype(int)\n",
    "\n",
    "# 4. Análise de distribuição\n",
    "print(\"\\nDistribuição do target:\")\n",
    "print(df_merged[\"target\"].value_counts(normalize=True))\n",
    "\n",
    "# 5. Filtrar dados inconclusivos (opcional)\n",
    "df_modelo = df_merged[\n",
    "    ~df_merged[\"situacao_candidado\"].str.contains(\n",
    "        \"avaliação|Encaminhado|Prospect\", na=False, case=False\n",
    "    )\n",
    "]\n",
    "\n",
    "# Verificar resultado\n",
    "print(\"\\nDataFrame após filtro:\")\n",
    "print(df_modelo[\"situacao_candidado\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dde505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status considerados como sucesso (1)\n",
    "sucesso = [\n",
    "    \"Contratado pela Decision\",\n",
    "    \"Contratado como Hunting\",\n",
    "    \"Aprovado\",\n",
    "    \"Proposta Aceita\",\n",
    "]\n",
    "\n",
    "# Criando a variável target\n",
    "df_merged[\"target\"] = df_merged[\"situacao_candidado\"].apply(\n",
    "    lambda x: 1 if x in sucesso else 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c800e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Definir status de sucesso\n",
    "status_sucesso = [\n",
    "    \"Contratado pela Decision\",\n",
    "    \"Contratado como Hunting\",\n",
    "    \"Aprovado\",\n",
    "    \"Proposta Aceita\",\n",
    "]\n",
    "\n",
    "# 2. Criar target binário\n",
    "df_merged[\"target\"] = df_merged[\"situacao_candidado\"].isin(status_sucesso).astype(int)\n",
    "\n",
    "# 3. Análise de distribuição\n",
    "print(\"\\nDistribuição do target:\")\n",
    "print(df_merged[\"target\"].value_counts(normalize=True))\n",
    "\n",
    "# 4. Filtrar dados inconclusivos (opcional)\n",
    "df_modelo = df_merged[\n",
    "    ~df_merged[\"situacao_candidado\"].str.contains(\"avaliação|Encaminhado|Prospect\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8165791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_merged[\"target\"].value_counts().plot.pie(\n",
    "    autopct=\"%.1f%%\",\n",
    "    labels=[\"Não Contratado\", \"Contratado\"],\n",
    "    colors=[\"#ff9999\", \"#66b3ff\"],\n",
    ")\n",
    "plt.title(\"Proporção de Contratações (Target)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter para string e substituir NaN por string vazia\n",
    "df_merged[\"situacao_candidado\"] = (\n",
    "    df_merged[\"situacao_candidado\"].astype(str).replace(\"nan\", \"\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora podemos aplicar o filtro corretamente\n",
    "df_modelo = df_merged[\n",
    "    ~df_merged[\"situacao_candidado\"].str.contains(\n",
    "        \"avaliação|Encaminhado|Prospect\", na=False\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1666432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Converter a coluna para string e tratar nulos\n",
    "df_merged[\"situacao_candidado\"] = (\n",
    "    df_merged[\"situacao_candidado\"].astype(str).replace(\"nan\", \"\")\n",
    ")\n",
    "\n",
    "# 2. Definir status de sucesso\n",
    "status_sucesso = [\n",
    "    \"Contratado pela Decision\",\n",
    "    \"Contratado como Hunting\",\n",
    "    \"Aprovado\",\n",
    "    \"Proposta Aceita\",\n",
    "]\n",
    "\n",
    "# 3. Criar target binário\n",
    "df_merged[\"target\"] = df_merged[\"situacao_candidado\"].isin(status_sucesso).astype(int)\n",
    "\n",
    "# 4. Análise de distribuição\n",
    "print(\"\\nDistribuição do target:\")\n",
    "print(df_merged[\"target\"].value_counts(normalize=True))\n",
    "\n",
    "# 5. Filtrar dados inconclusivos (opcional)\n",
    "df_modelo = df_merged[\n",
    "    ~df_merged[\"situacao_candidado\"].str.contains(\n",
    "        \"avaliação|Encaminhado|Prospect\", na=False, case=False\n",
    "    )\n",
    "]\n",
    "\n",
    "# Verificar resultado\n",
    "print(\"\\nDataFrame após filtro:\")\n",
    "print(df_modelo[\"situacao_candidado\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1994310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas categóricas relevantes\n",
    "cat_features = [\n",
    "    \"modalidade\",\n",
    "    \"formacao_e_idiomas.nivel_ingles\",\n",
    "    \"formacao_e_idiomas.nivel_espanhol\",\n",
    "    \"informacoes_pessoais.sexo\",\n",
    "    \"informacoes_pessoais.estado_civil\",\n",
    "]\n",
    "\n",
    "# Colunas de texto para processamento NLP\n",
    "text_features = [\n",
    "    \"comentario\",\n",
    "    \"cv_pt\",\n",
    "    \"informacoes_profissionais.conhecimentos_tecnicos\",\n",
    "]\n",
    "\n",
    "# Colunas numéricas (precisamos criar algumas)\n",
    "num_features = [\n",
    "    # Serão criadas a partir das datas\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23154661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, date_cols):\n",
    "        self.date_cols = date_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.date_cols:\n",
    "            if col in X.columns:\n",
    "                # Convert to datetime and extract features\n",
    "                dates = pd.to_datetime(X[col], errors=\"coerce\")\n",
    "                X[f\"{col}_year\"] = dates.dt.year\n",
    "                X[f\"{col}_month\"] = dates.dt.month\n",
    "                X[f\"{col}_day\"] = dates.dt.day\n",
    "                X[f\"{col}_dayofweek\"] = dates.dt.dayofweek\n",
    "        return X\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cf68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.sparse import issparse\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "# 1. Criar um transformador para converter esparso para denso quando necessário\n",
    "class SparseToDense(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        return X\n",
    "\n",
    "\n",
    "# 2. Definir as colunas para pré-processamento\n",
    "cat_features = [\"modalidade\", \"formacao_e_idiomas.nivel_ingles\"]\n",
    "text_features = [\"comentario\", \"cv_pt\"]\n",
    "\n",
    "# 3. Criar o pré-processador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text1\", TfidfVectorizer(max_features=100), \"comentario\"),\n",
    "        (\"text2\", TfidfVectorizer(max_features=50), \"cv_pt\"),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# 4. Pipeline final corrigido\n",
    "final_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"to_dense\", SparseToDense()),  # Conversão explícita aqui\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            RandomForestClassifier(class_weight=\"balanced\", random_state=42),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. Preparar e treinar\n",
    "X = df_merged[cat_features + text_features].fillna(\"\")\n",
    "y = df_merged[\"target\"]\n",
    "\n",
    "try:\n",
    "    final_pipeline.fit(X, y)  # Note que agora usamos final_pipeline, não pipeline\n",
    "    print(\"Pipeline treinado com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a90f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import time\n",
    "\n",
    "# 1. Reduza o número de folds e use n_jobs\n",
    "start = time.time()\n",
    "cv_results = cross_validate(\n",
    "    final_pipeline,\n",
    "    X,\n",
    "    y,\n",
    "    cv=3,  # Reduz de 5 para 3 folds\n",
    "    n_jobs=-1,  # Usa todos os cores do CPU\n",
    "    scoring=[\"f1\", \"roc_auc\"],\n",
    "    verbose=1,  # Mostra progresso\n",
    ")\n",
    "print(f\"Tempo total: {time.time() - start:.2f} segundos\")\n",
    "\n",
    "# 2. Métricas rápidas\n",
    "print(\"\\nF1-Score médio:\", cv_results[\"test_f1\"].mean())\n",
    "print(\"AUC-ROC médio:\", cv_results[\"test_roc_auc\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders import TargetEncoder\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f06a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"../data/processed/merged_data.csv\")\n",
    "df.shape, df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0759f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identificar colunas categóricas e numéricas\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Pipeline de transformação\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"cat\", TargetEncoder(), cat_cols),\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols)\n",
    "])\n",
    "\n",
    "# TF-IDF em texto (se houver campo)\n",
    "# Exemplo fictício: \"descricao_perfil\" — pode substituir conforme seu dataset\n",
    "if \"descricao_perfil\" in X.columns:\n",
    "    preprocessor.transformers.append(\n",
    "        (\"txt\", TfidfVectorizer(max_features=100), \"descricao_perfil\")\n",
    "    )\n",
    "\n",
    "# Construção do pipeline final\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"CLASSIFICATION REPORT:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC: \", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801af822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exportar o modelo treinado\n",
    "joblib.dump(clf, \"modelo_randomforest_match.pkl\")\n",
    "print(\"Modelo salvo com sucesso para uso no Streamlit!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
